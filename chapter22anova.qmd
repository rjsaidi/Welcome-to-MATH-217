---
title: "Chapter 22 interactive notes"
author: "R Saidi"
format: docx
editor: visual
---

## Load the libraries and data

Load this data from the class

```{r}
library(tidyverse)
library(tidymodels)
library(openintro)
data("nycflights")
head(nycflights)
```

The nycflights dataset has 32735 observations with 16 variables, including flight origin (origin) and arrival delay (arr_delay)

## What are the origin airports?

```{r}
unique(nycflights$origin)
```

"JFK" (Kennedy Airport) "LGA" (Laguardia Airport) "EWR" (Newark Airport)

## Before performing ANOVA, check conditions

### Constant variance?

```{r}
summarytable <- nycflights |>
  # Group by origin
  group_by(origin) |>
  # Calculate the std dev of arrival delay as std_delay
  #summarise(sd_delay = sd(arr_delay))
  summarise(mean_delay = mean(arr_delay), sd_delay = sd(arr_delay), median_delay = median(arr_delay), count = n())
summarytable
```

*The standard deviations do not appear too different.*

## Generate a sample from the "population" of flights in 2013

use this for all other calculations

```{r}
set.seed(935)
samp <- sample_n(nycflights, 200, replace = TRUE)
head(samp)
```

## Is there a difference in mean arrival delay among the 3 NYC airports?

Ho: There is no difference in mean arrival delay among the three NYC airports.

Ha: At least one airport's mean arrival delay is different.

```{r}
summarytable <- samp |>
  # Group by origin
  group_by(origin) |>
  # Calculate the std dev of arrival delay as std_delay
  #summarise(sd_delay = sd(arr_delay))
  summarise(mean_delay = mean(arr_delay), sd_delay = sd(arr_delay), median_delay = median(arr_delay), count = n())
summarytable
```

## Create boxplots density ridges plot to compare the 3 group distributions

```{r}
ggplot(samp, aes(origin, arr_delay, fill = origin)) +
         geom_boxplot()
```

```{r}
# install the package ggridges
library(ggridges)
samp |>
  # Map wordsum to the x-axis and class to the y-axis
  ggplot(aes(x = arr_delay, y = origin)) +
  # Add density ridges to the plot! 
  geom_density_ridges(aes(fill = origin), alpha = 0.5) +
  scale_fill_brewer(palette = "Dark2")
```

*Again, the distributions appear very similar.*


```{r}
samp |>
  # Map wordsum to the x-axis and class to the y-axis
  ggplot(aes(x = arr_delay)) +
  # Add density ridges to the plot! 
  geom_density(aes(fill = origin), alpha = 0.5) +
  scale_fill_brewer(palette = "Dark2")
```


```{r}
# Run an analysis of variance on score vs. rank
aov_delay_origin <- aov(arr_delay ~ origin, data = samp) #y~x
#summary(aov_delay_origin)
# Tidy the model
tidy(aov_delay_origin)
```

## Interpret the results

BUT from a random sample, the p-value is very large, meaning we fail to reject the null. This suggests that simply having a large sample size will coerce an effect, when there really is no effect.

There is no compelling evidence that there is a difference in mean arrival delay among the different origins.

## Simulating samples under the null hypothesis

### First calculate the observed statistic

In the case of an ANOVA, the statistic we are interested in is the F-statistic. While we can plot this statistic on an F-distribution, it really is just another statistic that we can calculate (like the mean or median). We like this statistic because it allows for us to summarize how different multiple means are from each other, relative to how variable the observations are within each group.

We can calculate the F-statistic using the tools from the infer package we are familiar with. The only part that is new is the stat that we calculate. Here, we use the "F" statistic.

```{r}
obs_stat <- samp |> 
  specify(arr_delay ~ origin) |>  #y~x
  calculate(stat = "F")
obs_stat
```

The next step is to simulate what we would expect for arrival delays to look like, if the null hypothesis was true. This is similar to the method for a difference in means, except now we have three groups: jfk, lga, and ewr. The underlying process, however, looks the same:

Step 1: Write the values of arr_delay on 32735 index cards (one card per person). Step 2: Shuffle the cards and randomly split them into three new piles, of the same size as the original groups. Step 3: Calculate and record the test statistic: F-statistic Step 4: Repeat steps (1) and (2) 1000 to generate the sampling distribution of the difference in means under the null hypothesis. Step 5: Calculate p-value as the percentage of simulations where the test statistic is at least as extreme as the observed F-statistic

```{r}
null_distr <- samp |>
 specify(arr_delay ~ origin) |> 
  hypothesize(null = "independence") |> 
  generate(reps = 1000, type = "permute") |> 
  calculate(stat = "F")
null_distr
```

```{r}
null_distr |> 
  visualise() +
  shade_p_value(obs_stat = obs_stat, direction = "greater")
```


```{r}
pvalue <- get_p_value(null_distr, obs_stat, direction = "greater")
pvalue
```


*We can see that the observed F-statistic is very close to zero. therefore we fail to reject the null. There is no compelling evidence that the mean arrival delay is different at at least one airport.*

## Post hoc testing

If you reject the null, now you can determine by pair-wise testing which group's mean is different using a "family" error rate, and then distribute that level to each of the tests we are performing. The "family" error rate specifies an overall Type I error rate we are willing to have for all of tests you wish to perform. We will use alpha = 0.05

There are many pairwise tests. We will use the TukeyHSD test on our original model, aov_delay_origin.

```{r}
TukeyHSD(aov_delay_origin)
```

## How to read this output

The p-adjusted values for comparing mean delays for JFK and EWR are not significant. The p-adjusted values for comparing mean delays for LGA and EWR are not significant. The p-adjusted values for comparing mean delays for LGA and JFK are not significant.

## Non-parametric test Kruskal Wallis Test

```{r}
# and on the sample
ktest_samp <- kruskal.test(arr_delay ~ origin, data = samp) #syntax is y~x
ktest_samp
```

*The conclusion is: With a large p-value, we fail to reject the null. There is no compelling evidence that there is a difference in distributions for arrival delays based on the airport of origin in NY.*

## Post hoc test for Kruskal Wallis test

If your p-value is small for the ktest (at least one group's distribution is shifted), the post-hoc test is the Dunn Test.

```{r}
library(dunn.test)
dunn.test(samp$arr_delay, samp$origin) # syntax is dunn.test(df$y, df$x)
```

## Here is an example where we reject the null

Use the fastfood dataset from openintro

```{r}
# from openintro
data(fastfood)
head(fastfood)
```

## Is there a difference in mean number of calories overall among the fast food restaurants?

Ho: There is no difference in overall mean number of calories among the fast food restaurants.

Ha: At least one restaurant's overall mean number of calories is different among the fast food restaurants.

```{r}
unique(fastfood$restaurant)
```

## There are 8 fast food restaurants.

## Check the basic conditions. First, create a table of counts.

```{r}
fast <- fastfood|>
group_by(restaurant) |>
summarise(mean_calorie = mean(calories), sd_calories = sd(calories), count = n())
fast
```

## Check the distributions of calories over the restaurants with ridge plots

```{r}
library(ggridges)
ggplot(fastfood, aes(x=calories, y=restaurant))+
  geom_density_ridges(aes(fill = restaurant), alpha = 0.5) +
  scale_fill_brewer(palette = "Dark2")
```

*We can see that the all the distributions of calories are right skewed, but they do seem a bit different.*

## Since the basic conditions may have been met, we can use ANOVA test.

Alternatively, we could use Kruskal Wallis test (below)

```{r}
aov_calories <- aov(calories ~ restaurant, data = fastfood)
tidy(aov_calories)
```

*The p value is very small. Reject the null. At least one restaurant's mean overall calories is different.*

## Perform the TukeyHSD post-hoc test for pairwise comparisons

```{r}
TukeyHSD(aov_calories)
```

\*Look for each of the pairwise comparisons that have small p-adj values. Those are the pairs with meaningfully different overall calories.

```{r}
# Chick Fil-A-Burger King -224.126984 -412.46039 -35.793574 0.0077024
# Taco Bell-Burger King   -164.919255 -290.94531 -38.893203 0.0019839
# Mcdonalds-Chick Fil-A    255.906433   61.68697 450.125891 0.0017798
# Sonic-Chick Fil-A        247.253669   50.69256 443.814773 0.0036044
# Subway-Mcdonalds        -137.330044 -276.33973   1.679647 0.0555520
# Taco Bell-Mcdonalds     -196.698703 -331.36232 -62.035084 0.0002868
# Taco Bell-Sonic         -188.045939 -326.06536 -50.026521 0.0010247
```

## Perform the same test using the non-parametric approach

```{r}
ktest <- kruskal.test(calories ~ restaurant, data =fastfood)
ktest
```

*Note the small pvalue. Reject the null. At least one restaurant's distribution of calories is different.*

```{r}
library(dunn.test)
dunn.test(fastfood$calories, fastfood$restaurant)
```
